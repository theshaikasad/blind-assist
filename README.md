 # ðŸ§  Blind Assistance Device Using AI and Computer Vision

> ðŸ‘ï¸ "Eyes might fail. This never will."  
A smart, AI-powered assistive system designed for visually impaired users. It provides real-time object detection, proximity alerts, and voice-based scene descriptions using just a webcam and speaker/headphones.

Team Project by:

- [Shaik Mohammed Asad](https://github.com/theshaikasad)
- [Revant Thakkar](https://github.com/Revant15)
---

## ðŸ” Features

- âœ… Real-time object detection using MobileNet SSD
- ðŸŽ¯ Proximity-based warnings with audio alerts
- ðŸ—£ï¸ Press a key to hear all detected objects in the frame
- ðŸŽ§ Works with Bluetooth headphones or speakers
- ðŸ§  Runs efficiently on low-power devices like Raspberry Pi

---

## ðŸŽ¯ Use Case

This project helps visually impaired individuals understand their environment by identifying and announcing nearby objects and warning them when an object is dangerously close.

---

## ðŸ§° Components Used

- Raspberry Pi (or any Linux desktop)
- USB Webcam
- Bluetooth/Wired Speaker or Headphones
- Python 3.8+
- MobileNet SSD (Caffe model)
- Libraries: `opencv-python`, `pyttsx3`, `playsound`, `threading`

---

## âš™ï¸ Setup Instructions

```bash
# Clone the repository
git clone https://github.com/your-username/blind-assist-device.git
cd blind-assist-device

# Create virtual environment
python3 -m venv blind-env
source blind-env/bin/activate

# Install dependencies
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Run

```bash
python blind_assist.py
```

- Press `Spacebar` to get a verbal list of all detected objects.
- The system will automatically **warn** if something is **too close** (e.g., a person or wall).
- Press `Q` to quit the program.

---

## ðŸ“· Screenshots


```markdown
![Object Detection Frame](media/frame_demo.png)
```

> ðŸ“Œ Recommended structure:
```
blind-assist-device/
â”‚
â”œâ”€â”€ blind_assist.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ media/
    â”œâ”€â”€ frame_demo.png
    â””â”€â”€ system_diagram.png
```

---

## ðŸ’¡ Future Improvements

- Add GPS navigation integration
- Use YOLOv8-Nano for faster inference
- Implement voice command support
- Add obstacle avoidance using ultrasonic sensors

---

## ðŸ“„ License

This project is licensed under the [MIT License](LICENSE).
